# Slide 1 â€” TÃ­tulo

## AnÃ¡lise de GeneralizaÃ§Ã£o em Redes Neurais para RegressÃ£o

### ValidaÃ§Ã£o Cruzada K-Fold e OtimizaÃ§Ã£o Bayesiana (Optuna)

---

**Autor:** CauÃ£ Vitor Figueredo Silva  

**MatrÃ­cula:** 20220014216  

**UFRN - Engenharia ElÃ©trica - ELE 604**  

**Novembro de 2025**

---

# Slide 2 â€” Contexto e Objetivos

### ğŸ¯ O Desafio: Small Data & Overfitting

O dataset **Boston Housing** possui apenas **506 amostras**. O risco de o modelo "memorizar" os dados Ã© alto.

**Problema Inicial:** Gap treino-validaÃ§Ã£o de **181%** (overfitting severo)

### ğŸš€ Objetivos do Projeto

1. **Pipeline MLOps:** Implementar fluxo robusto de ponta a ponta.

2. **GeneralizaÃ§Ã£o:** Garantir performance realÃ­stica via **K-Fold (K=5)**.

3. **RegularizaÃ§Ã£o:** Mitigar overfitting (Dropout + L2 + Early Stopping).

4. **SOTA (State of the Art):** Maximizar mÃ©tricas via **OtimizaÃ§Ã£o Bayesiana**.

---

# Slide 3 â€” AnÃ¡lise dos Dados

### ğŸ“Š Boston Housing Dataset

- **Target:** `MEDV` (PreÃ§o mediano em US$ 1000)

- **DimensÃµes:** 506 amostras Ã— 13 features

### Features CrÃ­ticas (CorrelaÃ§Ã£o Alta)

- **LSTAT (-0.74):** % populaÃ§Ã£o de baixa renda (CorrelaÃ§Ã£o Negativa)

- **RM (+0.70):** NÃºmero de quartos (CorrelaÃ§Ã£o Positiva)

- **PTRATIO (-0.51):** RazÃ£o aluno-professor

> **Ponto de AtenÃ§Ã£o:** A escassez de dados exige validaÃ§Ã£o cruzada para evitar viÃ©s de seleÃ§Ã£o.

**(Inserir: Histograma da variÃ¡vel alvo MEDV ou Matriz de CorrelaÃ§Ã£o)**

---

# Slide 4 â€” Pipeline de PrÃ©-processamento (Data Leakage)

### ğŸ›¡ï¸ A Regra de Ouro do MLOps

Evitar que informaÃ§Ãµes de validaÃ§Ã£o vazem para o treino.

**Fluxo Correto (Implementado):**

1. **DivisÃ£o K-Fold:** SeparaÃ§Ã£o dos Ã­ndices.

2. **Fit no Treino:** `scaler.fit(X_train)` 

3. **Transform no Resto:** `scaler.transform(X_val)`

### NormalizaÃ§Ã£o

- **MÃ©todo:** Z-Score (StandardScaler)

- **Impacto:** EstabilizaÃ§Ã£o dos gradientes e convergÃªncia mais rÃ¡pida do otimizador Adam.

**(Inserir: Diagrama simples de blocos mostrando o Scaler dentro do loop K-Fold)**

---

# Slide 5 â€” Arquitetura da Rede Neural

### ğŸ§  Multi-Layer Perceptron (MLP) DinÃ¢mico

```mermaid
graph LR
    Input[Input (13)] --> H1[Hidden 1 (64) + ReLU]
    H1 --> Drop1[Dropout 30%]
    Drop1 --> H2[Hidden 2 (32) + ReLU]
    H2 --> Drop2[Dropout 30%]
    Drop2 --> Out[Output (1)]
```

*Nota: Se o ambiente nÃ£o suportar Mermaid, usar imagem PNG do diagrama como backup.*

### Componentes Chave

- **RegularizaÃ§Ã£o Ativa:**
  - **Dropout (0.3):** Desliga 30% dos neurÃ´nios aleatoriamente.
  - **L2 (Weight Decay 1e-4):** Penaliza pesos de alta magnitude.

- **OtimizaÃ§Ã£o:**
  - **Algoritmo:** Adam (`lr=0.001`)
  - **Loss:** MSE (Mean Squared Error)

---

# Slide 6 â€” EstratÃ©gias de Treinamento

### âš™ï¸ Controle de Overfitting

| TÃ©cnica | ConfiguraÃ§Ã£o | BenefÃ­cio |
|:---:|:---:|:---|
| **K-Fold** | $K=5$ | Estimativa de erro robusta (MÃ©dia Â± Desvio PadrÃ£o). |
| **Early Stopping** | Patience=20 | Para o treino se `val_loss` estagnar. Economia de **70%** de tempo. |
| **Model Checkpointing** | `best_model.pth` | Garante que o modelo final Ã© o de menor erro, nÃ£o o Ãºltimo. |

---

# Slide 7 â€” OtimizaÃ§Ã£o Bayesiana (AutoML)

### ğŸ”¬ Por que Optuna?

Diferente do Grid Search (forÃ§a bruta), o **TPE Sampler** aprende com os erros passados.

- **Trials:** 20 iteraÃ§Ãµes

- **Tempo:** ~25 minutos (vs ~5h de Grid Search estimado)

- **Pruning:** O algoritmo **Hyperband** mata treinos ruins no inÃ­cio.

### EspaÃ§o de Busca

- **Camadas:** 1 a 3

- **NeurÃ´nios:** 16 a 128

- **Dropout:** 0.1 a 0.5

- **Otimizador:** Adam vs RMSprop

**(Inserir: `reports/figures/optuna_optimization_history.png` - Painel HistÃ³rico)**

---

# Slide 8 â€” Resultados Visuais: ConvergÃªncia

### ğŸ“‰ Curvas de Aprendizado (Loss)

**(Inserir: `reports/figures/learning_curves.png` lado a lado com `learning_curves_optimized.png`)**

### AnÃ¡lise Comparativa

1. **Modelo Base:** ConvergÃªncia estÃ¡vel, mas com gap moderado.

2. **Modelo Otimizado:** ConvergÃªncia mais rÃ¡pida e **gap reduzido**.

3. **DiagnÃ³stico:** AusÃªncia de "boca de jacarÃ©" (divergÃªncia) indica sucesso no combate ao overfitting.

---

# Slide 9 â€” Resultados Quantitativos

### ğŸ† ComparaÃ§Ã£o de Performance (MÃ©dia 5-Folds)

| MÃ©trica | Modelo Base | Modelo Otimizado | VariaÃ§Ã£o |
|:---|:---:|:---:|:---:|
| **MSE (Erro)** | 13.47 | **13.02** | ğŸ”» **3.3%** (Melhor) |
| **RÂ² (Ajuste)** | 0.852 | **0.857** | ğŸ”º **0.5%** (Melhor) |
| **Desvio PadrÃ£o** | **2.47** | 4.62 | ğŸ”¸ Aumento de variÃ¢ncia |

### Insight

O modelo otimizado Ã© **mais preciso** na mÃ©dia, embora apresente maior sensibilidade entre os folds (trade-off viÃ©s-variÃ¢ncia).

---

# Slide 10 â€” Qualidade das PrediÃ§Ãµes

### ğŸ¯ Real vs Predito

**(Inserir: `reports/figures/predictions_scatter_optimized.png` ocupando a esquerda)**

**InterpretaÃ§Ã£o Visual:**

- **AderÃªncia:** Pontos agrupados prÃ³ximos Ã  linha vermelha tracejada ($y=x$).

- **Erro MÃ©dio:** ~$3.600 (em imÃ³veis de ~$22.500).

- **ResÃ­duos:** DistribuiÃ§Ã£o uniforme, sem viÃ©s sistemÃ¡tico para preÃ§os altos ou baixos.

---

# Slide 11 â€” AnÃ¡lise de GeneralizaÃ§Ã£o

### âœ… ClassificaÃ§Ã£o: Boa GeneralizaÃ§Ã£o

O gap entre treino e validaÃ§Ã£o foi reduzido drasticamente:

- **Sem RegularizaÃ§Ã£o:** Gap ~181% (Overfitting severo)

- **Com MLOps:** Gap **~35%** (ReduÃ§Ã£o de **80%**)

### MÃ©tricas Finais

- **RÂ² MÃ©dio:** **0.857** (85.7% da variÃ¢ncia explicada)

- **Erro MÃ©dio:** ~$3.60k em preÃ§os de ~$22.5k (**16%** erro relativo)

### LimitaÃ§Ãµes Identificadas

1. **Fold 3 (Outlier):** No modelo otimizado, um fold teve MSE=21.03, puxando o desvio padrÃ£o para cima.

2. **Capacidade do Modelo:** Com apenas 506 dados, arquiteturas mais profundas (3+ camadas) nÃ£o trouxeram ganhos significativos.

---

# Slide 12 â€” Destaques do Projeto (Highlights)

### ğŸŒŸ O que foi alcanÃ§ado

1. **ReduÃ§Ã£o de Overfitting:** De 181% para **35%** de gap.

2. **PrecisÃ£o:** Capacidade de explicar **85.7%** da variÃ¢ncia dos preÃ§os ($R^2$).

3. **EficiÃªncia:** OtimizaÃ§Ã£o de hiperparÃ¢metros em **25 minutos**.

4. **Robustez:** ValidaÃ§Ã£o em 5 cenÃ¡rios diferentes (Folds) garante que o resultado nÃ£o Ã© sorte.

---

# Slide 13 â€” ConclusÃµes e PrÃ³ximos Passos

### ConclusÃ£o

A combinaÃ§Ã£o de **RegularizaÃ§Ã£o (Dropout/L2)** com **OtimizaÃ§Ã£o Bayesiana** permitiu treinar uma rede neural robusta mesmo em um cenÃ¡rio de *Small Data*, superando as limitaÃ§Ãµes de overfitting comuns nesse contexto.

### ğŸš€ PrÃ³ximos Passos

- [ ] **Ensemble:** MÃ©dia dos 5 modelos do K-Fold para reduzir a variÃ¢ncia.

- [ ] **Feature Engineering:** Criar interaÃ§Ãµes nÃ£o-lineares (ex: $RM^2$).

- [ ] **Deploy:** Encapsular o melhor modelo em uma API com **FastAPI** e **Docker**.

---

# Slide 14 â€” Stack TecnolÃ³gico

### Ferramentas Utilizadas

- **Linguagem:** Python 3.12

- **Core ML:** PyTorch 2.0

- **OtimizaÃ§Ã£o:** Optuna 3.3 (TPE + Hyperband)

- **Pipeline:** Scikit-Learn (Pipeline, KFold)

- **VisualizaÃ§Ã£o:** Matplotlib & Seaborn

- **Ambiente:** Jupyter Notebook & LaTeX

---

# Slide 15 â€” ReferÃªncias Principais

1. **Hastie, T., et al. (2009).** *The Elements of Statistical Learning*.

2. **Goodfellow, I., et al. (2016).** *Deep Learning*.

3. **Akiba, T., et al. (2019).** *Optuna: A Next-generation Hyperparameter Optimization Framework*.

4. **Srivastava, N., et al. (2014).** *Dropout: A Simple Way to Prevent Neural Networks from Overfitting*.

**RepositÃ³rio do Projeto:**

`github.com/takaokensei/ufrn-ele-neural-regression`

---

# Slide 16 â€” Perguntas?

### Obrigado pela atenÃ§Ã£o!

**CauÃ£ Vitor Figueredo Silva**

`cauavitor@ufrn.edu.br`

UFRN - Engenharia ElÃ©trica
