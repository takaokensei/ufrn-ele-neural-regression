# ğŸ§  UFRN - Neural Regression Project

**AnÃ¡lise de GeneralizaÃ§Ã£o em Redes Neurais para RegressÃ£o de PreÃ§os ImobiliÃ¡rios com ValidaÃ§Ã£o Cruzada K-Fold**

---

## ğŸ“‹ InformaÃ§Ãµes do Projeto

- **InstituiÃ§Ã£o:** Universidade Federal do Rio Grande do Norte (UFRN)
- **Departamento:** Engenharia ElÃ©trica - Centro de Tecnologia
- **Autor:** CauÃ£ Vitor Figueredo Silva
- **MatrÃ­cula:** 20220014216
- **Data:** Novembro de 2025

---

## ğŸ¯ Objetivo

Este projeto implementa uma **Rede Neural Artificial (MLP)** para regressÃ£o de preÃ§os imobiliÃ¡rios utilizando o dataset Boston Housing. O foco principal Ã© a anÃ¡lise rigorosa de **generalizaÃ§Ã£o**, aplicando tÃ©cnicas de MLOps como:

- âœ… **K-Fold Cross-Validation (K=5)**
- âœ… **Early Stopping**
- âœ… **Model Checkpointing**
- âœ… **Data Leakage Prevention**
- âœ… **Reprodutibilidade (Seed Fixing)**

---

## ğŸ“‚ Estrutura do Projeto

```
ufrn-ele-neural-regression/
â”‚
â”œâ”€â”€ README.md              # DocumentaÃ§Ã£o e HistÃ³rico de VersÃµes
â”œâ”€â”€ requirements.txt       # DependÃªncias exatas (torch, pandas, numpy, etc.)
â”œâ”€â”€ .gitignore             # Arquivos a ignorar (dados, modelos, cache)
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/               # Dados brutos (boston.csv via URL)
â”‚   â””â”€â”€ processed/         # Dados normalizados (opcional)
â”‚
â”œâ”€â”€ notebooks/             # Ambiente de ExperimentaÃ§Ã£o
â”‚   â””â”€â”€ project_main.ipynb # Notebook principal com cÃ³digo completo
â”‚
â”œâ”€â”€ src/                   # CÃ³digo Modular (Simulado dentro do Notebook)
â”‚   â”œâ”€â”€ __init__.py        # Inicializador do pacote
â”‚   â”œâ”€â”€ dataset.py         # Carregamento e Dataset PyTorch
â”‚   â”œâ”€â”€ model.py           # Arquitetura MLP
â”‚   â”œâ”€â”€ train.py           # Loops de treino e validaÃ§Ã£o
â”‚   â””â”€â”€ visualization.py   # Plots de loss e scatter
â”‚
â”œâ”€â”€ models/                # Checkpoints
â”‚   â””â”€â”€ best_model_fold.pth
â”‚
â””â”€â”€ reports/               # RelatÃ³rio LaTeX
    â”œâ”€â”€ figures/           # Imagens geradas
    â””â”€â”€ relatorio_final.tex
```

### ğŸ“ DescriÃ§Ã£o das Pastas

| Pasta | FunÃ§Ã£o |
|-------|--------|
| `data/raw/` | Dados originais sem processamento |
| `data/processed/` | Dados apÃ³s normalizaÃ§Ã£o/transformaÃ§Ã£o |
| `notebooks/` | ExperimentaÃ§Ã£o e prototyping |
| `src/` | CÃ³digo modular e reutilizÃ¡vel |
| `models/` | Checkpoints dos melhores modelos |
| `reports/` | DocumentaÃ§Ã£o tÃ©cnica (LaTeX) |

---

## ğŸš€ Como Executar

### 1. Instalar DependÃªncias

```bash
pip install -r requirements.txt
```

### 2. Executar o Notebook Principal

```bash
jupyter notebook notebooks/project_main.ipynb
```

### 3. Compilar o RelatÃ³rio LaTeX

```bash
cd reports
pdflatex relatorio_final.tex
```

---

## ğŸ“Š Dataset

**Boston Housing Dataset**
- **Fonte:** http://lib.stat.cmu.edu/datasets/boston
- **InstÃ¢ncias:** 506
- **Features:** 13 (CRIM, ZN, INDUS, CHAS, NOX, RM, AGE, DIS, RAD, TAX, PTRATIO, B, LSTAT)
- **Target:** MEDV (PreÃ§o mediano das casas em $1000)

---

## ğŸ—ï¸ Arquitetura da Rede Neural

```
Input Layer (13 features)
    â†“
Hidden Layer 1 (64 neurÃ´nios, ReLU)
    â†“
Hidden Layer 2 (32 neurÃ´nios, ReLU)
    â†“
Output Layer (1 neurÃ´nio, Linear)
```

**HiperparÃ¢metros:**
- Otimizador: Adam (lr=0.001)
- Loss Function: MSELoss
- Batch Size: 16
- Epochs: 500 (com Early Stopping)
- K-Fold: 5 splits

---

## ğŸ“ˆ Resultados Esperados

- **Curvas de Aprendizado:** ConvergÃªncia suave entre treino e validaÃ§Ã£o
- **Scatter Plot:** PrediÃ§Ãµes prÃ³ximas Ã  linha identidade (y=x)
- **MÃ©trica:** MSE mÃ©dio < 20.0 (apÃ³s K-Fold)

---

## ğŸ”„ HistÃ³rico de Commits Simulado

Este projeto foi desenvolvido seguindo um fluxo de trabalho incremental. Abaixo estÃ¡ o histÃ³rico de commits que representa a evoluÃ§Ã£o do cÃ³digo:

```
commit #01 - feat: initialize project structure
  â””â”€ CriaÃ§Ã£o da estrutura de diretÃ³rios (data, src, models, reports)
  â””â”€ AdiÃ§Ã£o de requirements.txt e .gitignore

commit #02 - feat: add data loading module
  â””â”€ ImplementaÃ§Ã£o de src/dataset.py
  â””â”€ FunÃ§Ã£o robusta para download do Boston Housing Dataset
  â””â”€ Tratamento de cabeÃ§alho complexo da URL original

commit #03 - feat: implement MLP architecture
  â””â”€ CriaÃ§Ã£o de src/model.py
  â””â”€ Classe MLP com 2 camadas ocultas
  â””â”€ UtilizaÃ§Ã£o de torch.nn.Module

commit #04 - feat: add preprocessing with StandardScaler
  â””â”€ IntegraÃ§Ã£o do StandardScaler no pipeline
  â””â”€ PrevenÃ§Ã£o de Data Leakage (fit apenas no treino)

commit #05 - feat: implement K-Fold Cross-Validation
  â””â”€ Loop manual de K-Fold (K=5)
  â””â”€ SeparaÃ§Ã£o correta de treino/validaÃ§Ã£o

commit #06 - feat: add training loop with validation
  â””â”€ ImplementaÃ§Ã£o de src/train.py
  â””â”€ Loop de treino com cÃ¡lculo de loss

commit #07 - feat: implement Early Stopping mechanism
  â””â”€ LÃ³gica de parada antecipada (patience=20)
  â””â”€ Monitoramento de val_loss para evitar overfitting

commit #08 - feat: add Model Checkpointing
  â””â”€ Salvamento automÃ¡tico do melhor modelo
  â””â”€ torch.save() e torch.load() integrados

commit #09 - fix: adjust learning rate for better convergence
  â””â”€ MudanÃ§a de lr=0.01 para lr=0.001
  â””â”€ Melhoria na estabilidade do treino

commit #10 - feat: add visualization module
  â””â”€ CriaÃ§Ã£o de src/visualization.py
  â””â”€ GrÃ¡fico de Learning Curves (train vs validation)
  â””â”€ Scatter Plot (Real vs Predito)

commit #11 - feat: implement seed fixing for reproducibility
  â””â”€ FixaÃ§Ã£o de seeds (torch, numpy, random)
  â””â”€ Garantia de resultados determinÃ­sticos

commit #12 - refactor: modularize code structure
  â””â”€ SeparaÃ§Ã£o de responsabilidades entre mÃ³dulos
  â””â”€ Type hints adicionados para melhor legibilidade

commit #13 - docs: add LaTeX report template
  â””â”€ CriaÃ§Ã£o de reports/relatorio_final.tex
  â””â”€ Estrutura ABNT com Introduction, Methodology, Results

commit #14 - feat: integrate metrics aggregation
  â””â”€ CÃ¡lculo de mÃ©dia e desvio padrÃ£o do MSE
  â””â”€ Tabela final com resultados do K-Fold

commit #15 - style: improve plot aesthetics
  â””â”€ Ajuste de fontes, cores e legendas
  â””â”€ GrÃ¡ficos profissionais para publicaÃ§Ã£o

commit #16 - test: validate data leakage prevention
  â””â”€ VerificaÃ§Ã£o manual do fluxo de normalizaÃ§Ã£o
  â””â”€ ConfirmaÃ§Ã£o de que scaler nÃ£o vÃª dados de validaÃ§Ã£o

commit #17 - docs: complete LaTeX report content
  â””â”€ Preenchimento de Introduction e Methodology
  â””â”€ AdiÃ§Ã£o de placeholders para tabelas de resultados

commit #18 - feat: add analysis of generalization
  â””â”€ CÃ©lula Markdown com anÃ¡lise final
  â””â”€ ClassificaÃ§Ã£o: Overfitting/Underfitting/GeneralizaÃ§Ã£o

commit #19 - docs: update README with usage instructions
  â””â”€ AdiÃ§Ã£o de seÃ§Ã£o "Como Executar"
  â””â”€ DocumentaÃ§Ã£o completa da estrutura do projeto

commit #20 - chore: final cleanup and organization
  â””â”€ RemoÃ§Ã£o de arquivos temporÃ¡rios
  â””â”€ ValidaÃ§Ã£o final de todos os mÃ³dulos
```

---

## ğŸ› ï¸ Tecnologias Utilizadas

- **PyTorch 2.0.1** - Framework de Deep Learning
- **scikit-learn 1.3.0** - PrÃ©-processamento e K-Fold
- **Pandas 2.0.2** - ManipulaÃ§Ã£o de dados
- **Matplotlib 3.7.1** - VisualizaÃ§Ã£o
- **NumPy 1.24.3** - OperaÃ§Ãµes numÃ©ricas

---

## ğŸ“ PrÃ³ximos Passos

- [ ] Experimentar arquiteturas mais profundas
- [ ] Testar regularizaÃ§Ã£o (Dropout, L2)
- [ ] Implementar Grid Search para hiperparÃ¢metros
- [ ] Adicionar anÃ¡lise de SHAP Values
- [ ] Deployar modelo via FastAPI

---

## ğŸ“„ LicenÃ§a

Este projeto Ã© de uso acadÃªmico para a disciplina de Engenharia ElÃ©trica da UFRN.

---

## ğŸ‘¤ Contato

**CauÃ£ Vitor Figueredo Silva**  
MatrÃ­cula: 20220014216  
UFRN - Departamento de Engenharia ElÃ©trica

